---
title: "Decision trees"
output:
  html_document:
    toc: yes
    toc_float: true
    theme: united

---

```{r}
library(rpart)
library(rpart.plot)
library(tidyverse)
```

## Read Data


```{r}

titanic_set <- read_csv(here::here("data/titanic_decision_tree_data.csv"))

shuffle_index <- sample(1:nrow(titanic_set))

titanic_set <- titanic_set[shuffle_index, ]



```

## Data Cleaning

Set the dataset that only contains `numeric` or `factor` type

```{r}


titanic_clean <- titanic_set %>%
  filter(survived %in% c(0,1)) %>%
# Convert to factor level
    mutate(sex = as.factor(sex), 
           age_status = as.factor(if_else(age <= 16, "child", "adult")),
         class = factor(pclass, levels = c(3,2,1), labels = c("Lower", "Middle", "Upper")), 
           survived_flag = factor(survived, levels = c(0,1), labels = c("No", "Yes")), 
           port_embarkation = as.factor(embarked)) %>%
  select(sex, age_status, class, port_embarkation, sib_sp, parch, survived_flag) %>%
  na.omit()


#Tried to do some codes but turns out the levels and label will affect creating train / test set

# titanic_clean <- titanic_set %>% 
#   
#   mutate(age_status = as.factor(if_else(age <= 16, "child", "adult"))) %>% 
#   mutate(across(.cols = c("sex", "survived", "pclass", "embarked"), ~ as.factor(.x))) %>% 
#   filter(survived %in% c(1,0)) %>% 
#   select(survived, age_status, sex, parch, sib_sp, pclass, embarked) %>% 
#   na.omit()
# 
#   glimpse(titanic_clean)

```


## Create training & testing dataset

```{r}
set.seed(50)
```


```{r}



# test_sample_index <- sample(1:titanic_clean, size = titanic_clean * 0.2)

titanic_test <- slice(titanic_clean, shuffle_index)

titanic_train <- slice(titanic_clean, -shuffle_index)


```

* For train_set the percentage is NaN, means there is no valid value. So the test set will be used to create decision trees

```{r}

titanic_test %>% 
  janitor::tabyl(survived_flag)

```


```{r}

titanic_train%>% 
  janitor::tabyl(survived_flag)

```


## Build model based on test dataset

```{r}

titanic_fit <- rpart(
  formula = survived_flag ~ .,
  data = titanic_test,
  method = "class"
)

rpart.plot(titanic_fit,
           fallen.leaves = TRUE,
           faclen = 6,
           digits = 4,
           extra = 101)

```

From the decision tree it shows that there is a close relationship between death and sex; while the `class` is another variable that correlated to the death rate as well.

## Create confusion matrix

```{r}

library(modelr)

titanic_test_pred <- titanic_test %>% 
  add_predictions(titanic_fit, type = "class")

titanic_test_pred

```



```{r}

library(yardstick)

```


```{r}


conf_mat <- titanic_test_pred %>% 
  conf_mat(truth = survived_flag, estimate = pred)

conf_mat

```


```{r}

accuracy <- titanic_test_pred %>% 
  accuracy(truth = survived_flag, estimate = pred)

accuracy 

```



```{r}

 titanic_test_pred %>% 
  sensitivity(truth = survived_flag, estimate = pred)

```



```{r}

titanic_test_pred %>% 
  specificity(truth = survived_flag, estimate = pred)


```

```{r}

library(caret)


confusionMatrix(titanic_test_pred$pred, titanic_test_pred$survived_flag)


```

* From the table of confusion matrix, it shows that the accuracy of the model is 0.8 with p-value < 2.2e-16. Which means the model generated by decision trees is reliable. 